{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortgage CrossValidation with GPU accelerating on XGBoost\n",
    "\n",
    "In this notebook, we will show you how to levarage GPU to accelerate mortgage CrossValidation on XGBoost to find out the best model given a group parameters.\n",
    "\n",
    "## Import classes\n",
    "First we need load some common classes that both GPU version and CPU version will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml.dmlc.xgboost4j.scala.spark.{XGBoostClassificationModel, XGBoostClassifier}\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.tuning.ParamGridBuilder\n",
    "import org.apache.spark.sql.types.{FloatType, IntegerType, StructField, StructType}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is new to xgboost-spark users is rapids.GpuDataReader and **rapids.CrossValidator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml.dmlc.xgboost4j.scala.spark.rapids.{CrossValidator, GpuDataReader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainParquetPath = /home/bobwang/jupyter/data/mortgage/cv/train\n",
       "evalParquetPath = /home/bobwang/jupyter/data/mortgage/cv/transform\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/bobwang/jupyter/data/mortgage/cv/transform"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainParquetPath=\"/home/bobwang/jupyter/data/mortgage/cv/train\"\n",
    "val evalParquetPath=\"/home/bobwang/jupyter/data/mortgage/cv/transform\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the schema of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelColName = delinquency_12\n",
       "schema = StructType(StructField(orig_channel,FloatType,true), StructField(first_home_buyer,FloatType,true), StructField(loan_purpose,FloatType,true), StructField(property_type,FloatType,true), StructField(occupancy_status,FloatType,true), StructField(property_state,FloatType,true), StructField(product_type,FloatType,true), StructField(relocation_mortgage_indicator,FloatType,true), StructField(seller_name,FloatType,true), StructField(mod_flag,FloatType,true), StructField(orig_interest_rate,FloatType,true), StructField(orig_upb,IntegerType,true), StructField(orig_loan_term,IntegerType,true), StructField(orig_ltv,FloatType,true), StructField(orig_cltv,FloatType,true), StructField(num_borrowers,FloatType,true), Str...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(orig_channel,FloatType,true), StructField(first_home_buyer,FloatType,true), StructField(loan_purpose,FloatType,true), StructField(property_type,FloatType,true), StructField(occupancy_status,FloatType,true), StructField(property_state,FloatType,true), StructField(product_type,FloatType,true), StructField(relocation_mortgage_indicator,FloatType,true), StructField(seller_name,FloatType,true), StructField(mod_flag,FloatType,true), StructField(orig_interest_rate,FloatType,true), StructField(orig_upb,IntegerType,true), StructField(orig_loan_term,IntegerType,true), StructField(orig_ltv,FloatType,true), StructField(orig_cltv,FloatType,true), StructField(num_borrowers,FloatType,true), Str..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelColName = \"delinquency_12\"\n",
    "val schema = StructType(List(\n",
    "    StructField(\"orig_channel\", FloatType),\n",
    "    StructField(\"first_home_buyer\", FloatType),\n",
    "    StructField(\"loan_purpose\", FloatType),\n",
    "    StructField(\"property_type\", FloatType),\n",
    "    StructField(\"occupancy_status\", FloatType),\n",
    "    StructField(\"property_state\", FloatType),\n",
    "    StructField(\"product_type\", FloatType),\n",
    "    StructField(\"relocation_mortgage_indicator\", FloatType),\n",
    "    StructField(\"seller_name\", FloatType),\n",
    "    StructField(\"mod_flag\", FloatType),\n",
    "    StructField(\"orig_interest_rate\", FloatType),\n",
    "    StructField(\"orig_upb\", IntegerType),\n",
    "    StructField(\"orig_loan_term\", IntegerType),\n",
    "    StructField(\"orig_ltv\", FloatType),\n",
    "    StructField(\"orig_cltv\", FloatType),\n",
    "    StructField(\"num_borrowers\", FloatType),\n",
    "    StructField(\"dti\", FloatType),\n",
    "    StructField(\"borrower_credit_score\", FloatType),\n",
    "    StructField(\"num_units\", IntegerType),\n",
    "    StructField(\"zip\", IntegerType),\n",
    "    StructField(\"mortgage_insurance_percent\", FloatType),\n",
    "    StructField(\"current_loan_delinquency_status\", IntegerType),\n",
    "    StructField(\"current_actual_upb\", FloatType),\n",
    "    StructField(\"interest_rate\", FloatType),\n",
    "    StructField(\"loan_age\", FloatType),\n",
    "    StructField(\"msa\", FloatType),\n",
    "    StructField(\"non_interest_bearing_upb\", FloatType),\n",
    "    StructField(labelColName, IntegerType)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new spark session and load data\n",
    "we must create a new spark session to continue all spark operations. It will also be used to initilize the `GpuDataReader` which is a data reader powered by GPU.\n",
    "\n",
    "NOTE: in this notebook, we have uploaded dependency jars when installing toree kernel. If we don't upload them at installation time, we can also upload in notebook by [%AddJar magic](https://toree.incubator.apache.org/docs/current/user/faq/). However, there's one restriction for `%AddJar`: the jar uploaded can only be available when `AddJar` is called after a new spark session is created. We must use it as below:\n",
    "\n",
    "```scala\n",
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().appName(\"Taxi-GPU\").getOrCreate\n",
    "%AddJar file:/data/libs/cudf-0.9.2-cuda10.jar\n",
    "%AddJar file:/data/libs/xgboost4j_2.x-1.0.0-Beta5.jar\n",
    "%AddJar file:/data/libs/xgboost4j-spark_2.x-1.0.0-Beta5.jar\n",
    "// ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@1a269120\n",
       "dataReader = ml.dmlc.xgboost4j.scala.spark.rapids.GpuDataReader@971fa92\n",
       "trainDs = ml.dmlc.xgboost4j.scala.spark.rapids.GpuDataset@2a6ccaf3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ml.dmlc.xgboost4j.scala.spark.rapids.GpuDataset@2a6ccaf3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder().appName(\"mortgage-gpu-cv\").getOrCreate()\n",
    "val dataReader = new GpuDataReader(spark)\n",
    "val trainDs = dataReader.parquet(trainParquetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out features to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureNames = List(orig_channel, first_home_buyer, loan_purpose, property_type, occupancy_status, property_state, product_type, relocation_mortgage_indicator, seller_name, mod_flag, orig_interest_rate, orig_upb, orig_loan_term, orig_ltv, orig_cltv, num_borrowers, dti, borrower_credit_score, num_units, zip, mortgage_insurance_percent, current_loan_delinquency_status, current_actual_upb, interest_rate, loan_age, msa, non_interest_bearing_upb)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(orig_channel, first_home_buyer, loan_purpose, property_type, occupancy_status, property_state, product_type, relocation_mortgage_indicator, seller_name, mod_flag, orig_interest_rate, orig_upb, orig_loan_term, orig_ltv, orig_cltv, num_borrowers, dti, borrower_credit_score, num_units, zip, mortgage_insurance_percent, current_loan_delinquency_status, current_actual_upb, interest_rate, loan_age, msa, non_interest_bearing_upb)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureNames = schema.filter(_.name != labelColName).map(_.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifierParam = Map(min_child_weight -> 30, grow_policy -> depthwise, scale_pos_weight -> 2, subsample -> 1, lambda -> 1, max_depth -> 10, num_round -> 100, missing -> 0.0, tree_method -> gpu_hist, eta -> 0.1, max_leaves -> 256, gamma -> 0.1, nthread -> 1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(min_child_weight -> 30, grow_policy -> depthwise, scale_pos_weight -> 2, subsample -> 1, lambda -> 1, max_depth -> 10, num_round -> 100, missing -> 0.0, tree_method -> gpu_hist, eta -> 0.1, max_leaves -> 256, gamma -> 0.1, nthread -> 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val classifierParam = Map(\n",
    "    \"eta\" -> 0.1,\n",
    "    \"gamma\" -> 0.1,\n",
    "    \"missing\" -> 0.0,\n",
    "    \"max_depth\" -> 10,\n",
    "    \"max_leaves\" -> 256,\n",
    "    \"grow_policy\" -> \"depthwise\",\n",
    "    \"objective\" -> \"binary:logistic\",\n",
    "    \"min_child_weight\" -> 30,\n",
    "    \"lambda\" -> 1,\n",
    "    \"scale_pos_weight\" -> 2,\n",
    "    \"subsample\" -> 1,\n",
    "    \"nthread\" -> 1,\n",
    "    \"num_round\" -> 100,\n",
    "    \"tree_method\" -> \"gpu_hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier = xgbc_ea83aa8bf675\n",
       "paramGrid = \n",
       "evaluator = mcEval_1515e4fb9ba5\n",
       "cv = cv_b280cf0ef9ce\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array({\n",
       "\txgbc_ea83aa8bf675-eta: 0.2,\n",
       "\txgbc_ea83aa8bf675-maxDepth: 3\n",
       "}, {\n",
       "\txgbc_ea83aa8bf675-eta: 0.6,\n",
       "\txgbc_ea83aa8bf675-maxDepth: 3\n",
       "}, {\n",
       "\txgbc_ea83aa8bf675-eta: 0.2,\n",
       "\txgbc_ea83aa8bf675-maxDepth: 10\n",
       "}, {\n",
       "\txgbc_ea83aa8bf675-eta: 0.6,\n",
       "\txgbc_ea83aa8bf675-maxDepth: 10\n",
       "})\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cv_b280cf0ef9ce"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val classifier = new XGBoostClassifier(classifierParam)\n",
    "    .setLabelCol(labelColName)\n",
    "    .setFeaturesCols(featureNames)\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "    .addGrid(classifier.maxDepth, Array(3, 10))\n",
    "    .addGrid(classifier.eta, Array(0.2, 0.6))\n",
    "    .build()\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(labelColName)\n",
    "val cv = new CrossValidator()\n",
    "    .setEstimator(classifier)\n",
    "    .setEvaluator(evaluator)\n",
    "    .setEstimatorParamMaps(paramGrid)\n",
    "    .setNumFolds(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9094, DMLC_NUM_WORKER=1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model = xgbc_ea83aa8bf675\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "xgbc_ea83aa8bf675"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = cv.fit(trainDs).asInstanceOf[XGBoostClassificationModel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tranform with best model trained by CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+----------+\n",
      "|delinquency_12|       rawPrediction|         probability|prediction|\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "|           0.0|[0.05490022897720...|[1.05490022897720...|       0.0|\n",
      "|           0.0|[0.00617653131484...|[1.00617653131484...|       0.0|\n",
      "|           0.0|[0.00617653131484...|[1.00617653131484...|       0.0|\n",
      "|           0.0|[0.00617653131484...|[1.00617653131484...|       0.0|\n",
      "|           0.0|[0.00617653131484...|[1.00617653131484...|       0.0|\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformDs = ml.dmlc.xgboost4j.scala.spark.rapids.GpuDataset@cb00757\n",
       "df = [orig_channel: float, first_home_buyer: float ... 29 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[orig_channel: float, first_home_buyer: float ... 29 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val transformDs = dataReader.parquet(evalParquetPath)\n",
    "val df = model.transform(transformDs).cache()\n",
    "df.drop(featureNames:_*).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -- 0.978318395457336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "evaluator = mcEval_2b9516126a6c\n",
       "accuracy = 0.978318395457336\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.978318395457336"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(labelColName)\n",
    "val accuracy = evaluator.evaluate(df)\n",
    "println(\"Accuracy -- \" + accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
